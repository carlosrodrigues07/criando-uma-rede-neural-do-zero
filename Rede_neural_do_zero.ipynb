{
  "nbformat": 4,
  "nbformat_minor": ,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision"
      ],
      "metadata": {
        "id": "ZGuxPIzIkFSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXa0DvsZAIq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jea3LWkhhVY0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "trainset = datasets.MNIST('./MNist_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform )\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "1ZvpIdMcjRcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo um batch de imagens\n",
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = next(dataiter)\n",
        "\n",
        "# Função para exibir a imagem\n",
        "def imshow(img):\n",
        "    img = img.numpy().squeeze()  # Converte o tensor para NumPy e remove dimensões extras\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "# Mostrando a primeira imagem do batch\n",
        "imshow(imagens[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "CRPmUvS1m62G",
        "outputId": "97c4726c-31cc-46a5-da3c-0417a4dfbdd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) # Para verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) #Para verificar a dimensão de cada etiqueta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyOFo90GxDKf",
        "outputId": "b34cbfb9-2039-42f8-dcc1-3d040f263f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do modelo\n",
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128)\n",
        "        self.linear2 = nn.Linear(128, 64)\n",
        "        self.linear3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)  # Achata a imagem\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "jES-rTFiyW5_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de treino\n",
        "def treino(modelo, trainloader, device):\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
        "    criterio = nn.NLLLoss()\n",
        "    EPOCHS = 10\n",
        "    modelo.train()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "            imagens = imagens.to(device)\n",
        "            etiquetas = etiquetas.to(device)\n",
        "\n",
        "            otimizador.zero_grad()\n",
        "\n",
        "            output = modelo(imagens)\n",
        "            perda_instantanea = criterio(output, etiquetas)\n",
        "            perda_instantanea.backward()\n",
        "            otimizador.step()\n",
        "\n",
        "            perda_acumulada += perda_instantanea.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} = Perda resultante: {perda_acumulada / len(trainloader)}\")\n",
        "    print(\"\\nTempo de treino (em minutos) =\", (time() - inicio) / 60)"
      ],
      "metadata": {
        "id": "DgMyZhMLzijq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de validação\n",
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "    modelo.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imagens, etiquetas in valloader:\n",
        "            imagens = imagens.to(device)\n",
        "            etiquetas = etiquetas.to(device)\n",
        "            output = modelo(imagens)\n",
        "\n",
        "            _, preds = torch.max(output, 1)\n",
        "            conta_corretas += (preds == etiquetas).sum().item()\n",
        "            conta_todas += etiquetas.size(0)\n",
        "\n",
        "    print(f\"Total de imagens testadas = {conta_todas}\")\n",
        "    print(f\"\\nPrecisão do modelo = {conta_corretas * 100 / conta_todas}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bvmBIMCQ3OLY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando o modelo e configurando o dispositivo\n",
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "id": "dAwRVd-I6LAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57b87ce-da17-44d5-a7db-fa203c817c98"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento e validação\n",
        "inicio = time()\n",
        "treino(modelo, trainloader, device)\n",
        "validacao(modelo, valloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li6icaHnF9R0",
        "outputId": "8bcc768c-e426-48cc-a439-f9f06db3ede0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 = Perda resultante: 1.178720623572498\n",
            "Epoch 2 = Perda resultante: 0.3746702851040531\n",
            "Epoch 3 = Perda resultante: 0.3044730971362799\n",
            "Epoch 4 = Perda resultante: 0.26511005990540804\n",
            "Epoch 5 = Perda resultante: 0.2352702773765905\n",
            "Epoch 6 = Perda resultante: 0.21052333419082134\n",
            "Epoch 7 = Perda resultante: 0.18988060043739485\n",
            "Epoch 8 = Perda resultante: 0.17265461977404445\n",
            "Epoch 9 = Perda resultante: 0.1578207561718439\n",
            "Epoch 10 = Perda resultante: 0.14552620649020045\n",
            "\n",
            "Tempo de treino (em minutos) = 1.8234300176302591\n",
            "Total de imagens testadas = 10000\n",
            "\n",
            "Precisão do modelo = 95.68%\n"
          ]
        }
      ]
    }
  ]
}
